{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"DESCRIPTION \u00b6 This is a living document for the HPC component of the MVP on AWS. This is a code repository and a living document describing ideas/\"how-tos\"/slides etc. related to the Minimal Viable Product (MVP) 1 to be built for the Genetics Branch (GB) on Cloud One or AWS. Disclaimer : There are two parallel efforts underway for the \"cloudification\" of GB, namely, a. Moving the database management and its web-interface to AWS also referred to as \"the Database component\" and b. Orchestrating NGS analysis workflows on AWS which is also referred to as \"the HPC compotent\" . This repository solely focuses on the HPC component . As MVP, we propose creating a basic RNAseq workflow on AWS using AWS CLI. We would like to use both the following pipelining frameworks: Snakemake Nextflow The code repository will hold the following: Snakemake pipeline Nextflow pipeline Recipes for Docker containers used by the pipeline and This documentation Please send your comments/questions/suggestions to Vishal Koparde . \u21a9","title":"Background"},{"location":"#description","text":"This is a living document for the HPC component of the MVP on AWS. This is a code repository and a living document describing ideas/\"how-tos\"/slides etc. related to the Minimal Viable Product (MVP) 1 to be built for the Genetics Branch (GB) on Cloud One or AWS. Disclaimer : There are two parallel efforts underway for the \"cloudification\" of GB, namely, a. Moving the database management and its web-interface to AWS also referred to as \"the Database component\" and b. Orchestrating NGS analysis workflows on AWS which is also referred to as \"the HPC compotent\" . This repository solely focuses on the HPC component . As MVP, we propose creating a basic RNAseq workflow on AWS using AWS CLI. We would like to use both the following pipelining frameworks: Snakemake Nextflow The code repository will hold the following: Snakemake pipeline Nextflow pipeline Recipes for Docker containers used by the pipeline and This documentation Please send your comments/questions/suggestions to Vishal Koparde . \u21a9","title":"DESCRIPTION"},{"location":"MVP/workflow/","text":"PIPELINE DETAILS \u00b6 RNAseq is one the most common NGS datatypes. It typically comes in two flavors: total RNAseq polyA RNAseq The core of most RNAseq data analysis workflows are mostly identical involving the following steps: trim fastq reads align trimmed reads to genome using split aware aligner count reads-per-gene based on existing gene model collect QC metrics at various stages The follow graphic depicts the basic workflow that we will attempt to create on AWS: INPUTS \u00b6 FASTA \u00b6 This is the genome in FASTA format. We will be using hg38 version of the human genome for our purposes and it can be downloaded from here . GTF \u00b6 GTF or Gene Transfer Format is a file which includes all the gene annotations or gene models. This includes the information about the location of the genes and their splicing events. We will use the GENCODEs release 38 for this. OUTPUTS \u00b6 The pipeline is expected to produce 2 primary outputs: CountsMatrix \u00b6 This is a tab-delimited file with nsample + 1 number of columns (first column is the gene identifier and it is followed by one column per sample of counts data) and ngenes + 1 number of rows (first row is the header containing sample names and every subsequent row gives counts per gene tab-delimited for each sample).","title":"Workflow"},{"location":"MVP/workflow/#pipeline-details","text":"RNAseq is one the most common NGS datatypes. It typically comes in two flavors: total RNAseq polyA RNAseq The core of most RNAseq data analysis workflows are mostly identical involving the following steps: trim fastq reads align trimmed reads to genome using split aware aligner count reads-per-gene based on existing gene model collect QC metrics at various stages The follow graphic depicts the basic workflow that we will attempt to create on AWS:","title":"PIPELINE DETAILS"},{"location":"MVP/workflow/#inputs","text":"","title":"INPUTS"},{"location":"MVP/workflow/#fasta","text":"This is the genome in FASTA format. We will be using hg38 version of the human genome for our purposes and it can be downloaded from here .","title":"FASTA"},{"location":"MVP/workflow/#gtf","text":"GTF or Gene Transfer Format is a file which includes all the gene annotations or gene models. This includes the information about the location of the genes and their splicing events. We will use the GENCODEs release 38 for this.","title":"GTF"},{"location":"MVP/workflow/#outputs","text":"The pipeline is expected to produce 2 primary outputs:","title":"OUTPUTS"},{"location":"MVP/workflow/#countsmatrix","text":"This is a tab-delimited file with nsample + 1 number of columns (first column is the gene identifier and it is followed by one column per sample of counts data) and ngenes + 1 number of rows (first row is the header containing sample names and every subsequent row gives counts per gene tab-delimited for each sample).","title":"CountsMatrix"}]}